{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on SNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from collections import Counter\n",
    "import pickle as pkl\n",
    "import random\n",
    "import pdb\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "random.seed(134)\n",
    "\n",
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def label2int(labels):\n",
    "    list = []\n",
    "    for word in labels:\n",
    "        if word == 'entailment':\n",
    "            list.append(0)\n",
    "        elif word == 'contradiction':\n",
    "            list.append(1)\n",
    "        else:\n",
    "            list.append(2)\n",
    "    return list\n",
    "  \n",
    "def tokenize(strings):\n",
    "    new = []\n",
    "    for line in strings:\n",
    "        split = line.split()\n",
    "        split[0] = split[0].lower()\n",
    "        new.append(split)\n",
    "    return new\n",
    "\n",
    "data = pd.read_table(\"snli_train.tsv\")\n",
    "val_data = pd.read_table(\"snli_val.tsv\")\n",
    "\n",
    "# data = data.iloc[:100,:]\n",
    "# val_data = val_data.iloc[:20,:]\n",
    "\n",
    "X = data.drop(['label'],axis=1)\n",
    "y = label2int(data['label'])\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "X_train = data.drop(['label'],axis=1)\n",
    "y_train = label2int(data['label'])\n",
    "\n",
    "stc1_train = tokenize(X_train['sentence1'])\n",
    "stc2_train = tokenize(X_train['sentence2'])\n",
    "# stc1_test = tokenize(X_test['sentence1'])\n",
    "# stc2_test = tokenize(X_test['sentence2'])\n",
    "stc1_val = tokenize(val_data['sentence1'])\n",
    "stc2_val = tokenize(val_data['sentence2'])\n",
    "y_val = label2int(val_data['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "def load_vectors(fname):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    cnt = 0\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        data[tokens[0]] = map(float, tokens[1:])\n",
    "        cnt = cnt + 1\n",
    "        if cnt > 50000:\n",
    "            break      \n",
    "    return data\n",
    "\n",
    "embedding_vectors = load_vectors('wiki-news-300d-1M.vec')\n",
    "\n",
    "def build_vocab(all_vectors):\n",
    "    # Returns:\n",
    "    # id2token: list of tokens, where id2token[i] returns token that corresponds to token i\n",
    "    # token2id: dictionary where keys represent tokens and corresponding values represent indices\n",
    "    max_len = max([len(key) for key in all_vectors])\n",
    "    vocab = all_vectors.keys()\n",
    "    id2token = list(vocab)\n",
    "    token2id = dict(zip(vocab, range(2,2+len(vocab)))) \n",
    "    id2token = ['<pad>', '<unk>'] + id2token\n",
    "    token2id['<pad>'] = PAD_IDX \n",
    "    token2id['<unk>'] = UNK_IDX\n",
    "    return token2id, id2token, max_len\n",
    "\n",
    "token2id, id2token, max_len = build_vocab(embedding_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size is 100000\n",
      "Val dataset size is 1000\n"
     ]
    }
   ],
   "source": [
    "# convert token to id in the dataset\n",
    "def token2index_dataset(tokens_data):\n",
    "    indices_data = []\n",
    "    for tokens in tokens_data:\n",
    "        index_list = [token2id[token] if token in token2id else UNK_IDX for token in tokens]\n",
    "        indices_data.append(index_list)\n",
    "    return indices_data\n",
    "\n",
    "stc1_train_indices = token2index_dataset(stc1_train)\n",
    "stc2_train_indices = token2index_dataset(stc2_train)\n",
    "stc1_val_indices = token2index_dataset(stc1_val)\n",
    "stc2_val_indices = token2index_dataset(stc2_val)\n",
    "stc1_test_indices = token2index_dataset(stc1_test)\n",
    "stc2_test_indices = token2index_dataset(stc2_test)\n",
    "\n",
    "# double checking\n",
    "print (\"Train dataset size is {}\".format(len(stc1_train_indices)))\n",
    "print (\"Val dataset size is {}\".format(len(stc1_val_indices)))\n",
    "# print (\"Test dataset size is {}\".format(len(stc1_test_indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENTENCE_LENGTH = max([len(sentence) for sentence in stc1_train])\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SNLIDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
    "    Note that this class inherits torch.utils.data.Dataset\n",
    "    \"\"\"\n",
    "    def __init__(self, stc1_data_list, stc2_data_list, target_list):\n",
    "        \"\"\"\n",
    "        @param data_list: list of newsgroup tokens \n",
    "        @param target_list: list of newsgroup targets \n",
    "\n",
    "        \"\"\"\n",
    "        self.stc1_data_list = stc1_data_list\n",
    "        self.stc2_data_list = stc2_data_list\n",
    "        self.target_list = target_list\n",
    "\n",
    "        assert (len(self.stc1_data_list) == len(self.target_list))\n",
    "        assert (len(self.stc1_data_list) == len(self.stc2_data_list))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.stc1_data_list)\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        stc1_token_idx = self.stc1_data_list[key][:MAX_SENTENCE_LENGTH]\n",
    "        stc2_token_idx = self.stc2_data_list[key][:MAX_SENTENCE_LENGTH]\n",
    "        label = self.target_list[key]\n",
    "#         print(len(stc1_token_idx),len(stc2_token_idx))\n",
    "        return [stc1_token_idx, stc2_token_idx, len(stc1_token_idx), len(stc2_token_idx), label]\n",
    "\n",
    "def SNLI_collate_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all \n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    data_list1 = []\n",
    "    data_list2 = []\n",
    "    label_list = []\n",
    "    length_list = []\n",
    "\n",
    "    for datum in batch:\n",
    "        label_list.append(datum[4])\n",
    "        length_list.append(datum[2])\n",
    "    # padding\n",
    "    for datum in batch:\n",
    "        padded_vec1 = np.pad(np.array(datum[0]),\n",
    "                                pad_width=((0,MAX_SENTENCE_LENGTH-datum[2])),\n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        data_list1.append(padded_vec1)\n",
    "        padded_vec2 = np.pad(np.array(datum[1]),\n",
    "                                pad_width=((0,MAX_SENTENCE_LENGTH-datum[3])),\n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        data_list2.append(padded_vec2)    \n",
    "        \n",
    "#     sorting decreasing order\n",
    "    ind_dec_order = np.argsort(length_list)[::-1]\n",
    "    data_list1 = np.array(data_list1)[ind_dec_order]\n",
    "    data_list2 = np.array(data_list2)[ind_dec_order]\n",
    "    length_list = np.array(length_list)[ind_dec_order]\n",
    "    label_list = np.array(label_list)[ind_dec_order]  \n",
    "    return [torch.from_numpy(np.array(data_list1)), torch.from_numpy(np.array(data_list2)),torch.LongTensor(length_list),torch.LongTensor(label_list)]\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "train_dataset = SNLIDataset(stc1_train_indices, stc2_train_indices, y_train)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=SNLI_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "val_dataset = SNLIDataset(stc1_val_indices,stc2_val_indices, y_val)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=SNLI_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_dataset = SNLIDataset(stc1_test_indices, stc2_test_indices, y_test)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=SNLI_collate_func,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, emb_size, hidden_size, num_layers, num_classes, vocab_size):\n",
    "        # RNN Accepts the following hyperparams:\n",
    "        # emb_size: Embedding Size\n",
    "        # hidden_size: Hidden Size of layer in RNN\n",
    "        # num_layers: number of layers in RNN\n",
    "        # num_classes: number of output classes\n",
    "        # vocab_size: vocabulary size\n",
    "        #      expected_hidden_size = (self.num_layers * num_directions, mini_batch, self.hidden_size)\n",
    "        # output (seq_len, batch, hidden_size * num_directions)\n",
    "        # h_n (num_layers * num_directions, batch, hidden_size)\n",
    "        super(RNN, self).__init__()\n",
    "        self.emb_size = emb_size\n",
    "        self.num_layers, self.hidden_size = num_layers, hidden_size\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size, padding_idx=PAD_IDX)\n",
    "        # what is batch dimension\n",
    "        # use following line for bidirectional GRU with num_layers = 1 dropout =1  \n",
    "        self.rnn = nn.GRU(emb_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.linear = nn.Linear(2*hidden_size, num_classes)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        # Function initializes the activation of recurrent neural net at timestep 0\n",
    "        # Needs to be in format (num_layers*num_directions, batch_size, hidden_size)\n",
    "        hidden = torch.randn(2*self.num_layers, batch_size, self.hidden_size)\n",
    "\n",
    "        return hidden\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        # reset hidden state\n",
    "\n",
    "        batch_size, seq_len = x.size()\n",
    "# implement the rnn from tensor \n",
    "        self.hidden = self.init_hidden(batch_size)\n",
    "\n",
    "        # get embedding of characters\n",
    "        embed = self.embedding(x)\n",
    "        m = (x == 1).type(torch.FloatTensor)\n",
    "        m = m.unsqueeze(2).repeat(1, 1, self.emb_size)\n",
    "        embed = m * embed + (1-m) * embed.clone().detach()\n",
    "        # pack padded sequence\n",
    "        # sequence length in descending order\n",
    "        embed = torch.nn.utils.rnn.pack_padded_sequence(embed, lengths.numpy(), batch_first=True)\n",
    "        # fprop though RNN\n",
    "        # rnn_out: batch size*sequence length*hidden dim\n",
    "        rnn_out, self.hidden = self.rnn(embed, self.hidden)\n",
    "        # undo packing\n",
    "        rnn_out, _ = torch.nn.utils.rnn.pad_packed_sequence(rnn_out, batch_first=True)\n",
    "# ends\n",
    "        self.hidden = self.dropout(self.hidden)\n",
    "        # the last hidden state \n",
    "        logits = self.hidden[0]\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/10], Step: [3125/3125],train acc: 46.875, Validation Acc: 52.0\n",
      "Epoch: [2/10], Step: [3125/3125],train acc: 50.0, Validation Acc: 55.6\n",
      "Epoch: [3/10], Step: [3125/3125],train acc: 56.25, Validation Acc: 57.6\n",
      "Epoch: [4/10], Step: [3125/3125],train acc: 68.75, Validation Acc: 59.4\n",
      "Epoch: [5/10], Step: [3125/3125],train acc: 53.125, Validation Acc: 59.4\n",
      "Epoch: [6/10], Step: [3125/3125],train acc: 65.625, Validation Acc: 60.9\n",
      "Epoch: [7/10], Step: [3125/3125],train acc: 62.5, Validation Acc: 60.2\n",
      "Epoch: [8/10], Step: [3125/3125],train acc: 65.625, Validation Acc: 61.5\n",
      "Epoch: [9/10], Step: [3125/3125],train acc: 59.375, Validation Acc: 59.3\n",
      "Epoch: [10/10], Step: [3125/3125],train acc: 65.625, Validation Acc: 60.7\n"
     ]
    }
   ],
   "source": [
    "# accuracy chart\n",
    "chart = pd.DataFrame()\n",
    "model = RNN(emb_size=100, hidden_size=100, num_layers=1, num_classes=3, vocab_size=len(id2token))\n",
    "# suppose in_features = 66\n",
    "rfc_model = nn.Sequential(nn.Linear(200, 200), nn.ReLU(inplace=True), nn.Linear(200, 3))\n",
    "\n",
    "learning_rate = 3e-4\n",
    "num_epochs = 10 # number epoch to train\n",
    "\n",
    "# Criterion and Optimizer\n",
    "# CrossEntropyLoss() combines nn.LogSoftmax() and nn.NLLLoss() in one single class\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "\n",
    "def test_model(loader, model):\n",
    "    \"\"\"\n",
    "    Help function that tests the model's performance on a dataset\n",
    "    @param: loader - data loader for the dataset to test against\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    for data1, data2, lengths, labels in loader:\n",
    "        data_batch1, data_batch2, lengths_batch, label_batch = data1, data2, lengths, labels\n",
    "        output1 = model(data_batch1, lengths_batch)\n",
    "        output2 = model(data_batch2, lengths_batch)\n",
    "        outputs = torch.cat([output1, output2], dim=1)\n",
    "        outputs = rfc_model(outputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        predicted = outputs.max(1, keepdim=True)[1]\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels.view_as(predicted)).sum().item()\n",
    "    return (100 * correct / total), loss\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i, (data1,data2,lengths,labels) in enumerate(train_loader):\n",
    "        outputs = 0\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        # [32, 400]\n",
    "        output1 = model(data1,lengths)\n",
    "        output2 = model(data2,lengths)     \n",
    "        outputs = torch.cat([output1, output2], dim=1)\n",
    "#         torch.Size([32, 400])\n",
    "        outputs = rfc_model(outputs)\n",
    "#     torch.Size([32, 3])\n",
    "        loss = criterion(outputs, labels)\n",
    "     \n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "#         # validate every 100 iterations\n",
    "#         if i > 0 and i % 100 == 0:\n",
    "    # validate\n",
    "    val_acc, val_loss = test_model(val_loader, model)    \n",
    "    predicted = outputs.max(1, keepdim=True)[1]\n",
    "    total += labels.size(0)\n",
    "    correct += predicted.eq(labels.view_as(predicted)).sum().item()\n",
    "    train_acc = 100 * correct / total\n",
    "    chart = chart.append(pd.Series([loss.item(), val_loss.item(), train_acc,val_acc]),ignore_index=True)    \n",
    "    print('Epoch: [{}/{}], Step: [{}/{}],train acc: {}, Validation Acc: {}'.format(\n",
    "                       epoch+1, num_epochs, i+1, len(train_loader), train_acc,val_acc))  \n",
    "    \n",
    "    \n",
    "chart.columns = ['train loss','val loss', 'train acc', 'val acc']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train loss</th>\n",
       "      <th>val loss</th>\n",
       "      <th>train acc</th>\n",
       "      <th>val acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.899823</td>\n",
       "      <td>0.994854</td>\n",
       "      <td>71.875</td>\n",
       "      <td>52.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.919549</td>\n",
       "      <td>0.893461</td>\n",
       "      <td>62.500</td>\n",
       "      <td>57.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.848188</td>\n",
       "      <td>0.768986</td>\n",
       "      <td>62.500</td>\n",
       "      <td>58.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.783004</td>\n",
       "      <td>0.704093</td>\n",
       "      <td>62.500</td>\n",
       "      <td>59.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.780601</td>\n",
       "      <td>0.783618</td>\n",
       "      <td>68.750</td>\n",
       "      <td>59.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.682274</td>\n",
       "      <td>1.044791</td>\n",
       "      <td>75.000</td>\n",
       "      <td>60.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.826559</td>\n",
       "      <td>0.771843</td>\n",
       "      <td>68.750</td>\n",
       "      <td>60.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.832078</td>\n",
       "      <td>1.279301</td>\n",
       "      <td>59.375</td>\n",
       "      <td>59.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.859190</td>\n",
       "      <td>1.118668</td>\n",
       "      <td>68.750</td>\n",
       "      <td>59.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.957020</td>\n",
       "      <td>1.126307</td>\n",
       "      <td>50.000</td>\n",
       "      <td>58.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train loss  val loss  train acc  val acc\n",
       "0    0.899823  0.994854     71.875     52.3\n",
       "1    0.919549  0.893461     62.500     57.1\n",
       "2    0.848188  0.768986     62.500     58.4\n",
       "3    0.783004  0.704093     62.500     59.9\n",
       "4    0.780601  0.783618     68.750     59.4\n",
       "5    0.682274  1.044791     75.000     60.2\n",
       "6    0.826559  0.771843     68.750     60.7\n",
       "7    0.832078  1.279301     59.375     59.9\n",
       "8    0.859190  1.118668     68.750     59.6\n",
       "9    0.957020  1.126307     50.000     58.6"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rnn, hidden_size = 100, no dropout\n",
    "chart1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train loss</th>\n",
       "      <th>val loss</th>\n",
       "      <th>train acc</th>\n",
       "      <th>val acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.962078</td>\n",
       "      <td>1.161669</td>\n",
       "      <td>46.875</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.042803</td>\n",
       "      <td>1.023585</td>\n",
       "      <td>50.000</td>\n",
       "      <td>55.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.959237</td>\n",
       "      <td>0.947626</td>\n",
       "      <td>56.250</td>\n",
       "      <td>57.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.818148</td>\n",
       "      <td>1.052669</td>\n",
       "      <td>68.750</td>\n",
       "      <td>59.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.968561</td>\n",
       "      <td>0.779647</td>\n",
       "      <td>53.125</td>\n",
       "      <td>59.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.815410</td>\n",
       "      <td>0.431272</td>\n",
       "      <td>65.625</td>\n",
       "      <td>60.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.936348</td>\n",
       "      <td>1.098801</td>\n",
       "      <td>62.500</td>\n",
       "      <td>60.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.826626</td>\n",
       "      <td>0.934144</td>\n",
       "      <td>65.625</td>\n",
       "      <td>61.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.806180</td>\n",
       "      <td>1.267943</td>\n",
       "      <td>59.375</td>\n",
       "      <td>59.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.852467</td>\n",
       "      <td>0.839534</td>\n",
       "      <td>65.625</td>\n",
       "      <td>60.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train loss  val loss  train acc  val acc\n",
       "0    0.962078  1.161669     46.875     52.0\n",
       "1    1.042803  1.023585     50.000     55.6\n",
       "2    0.959237  0.947626     56.250     57.6\n",
       "3    0.818148  1.052669     68.750     59.4\n",
       "4    0.968561  0.779647     53.125     59.4\n",
       "5    0.815410  0.431272     65.625     60.9\n",
       "6    0.936348  1.098801     62.500     60.2\n",
       "7    0.826626  0.934144     65.625     61.5\n",
       "8    0.806180  1.267943     59.375     59.3\n",
       "9    0.852467  0.839534     65.625     60.7"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rnn, hidden_size = 100, has dropout\n",
    "chart2 = chart\n",
    "chart2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, emb_size, hidden_size, num_layers, num_classes, vocab_size):\n",
    "\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.num_layers, self.hidden_size = num_layers, hidden_size\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size, padding_idx=PAD_IDX)\n",
    "    \n",
    "        self.conv1 = nn.Conv1d(emb_size, hidden_size, kernel_size=2, padding=1)\n",
    "        self.conv2 = nn.Conv1d(hidden_size, hidden_size, kernel_size=2, padding=1)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "        self.linear = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        batch_size, seq_len = x.size()\n",
    "\n",
    "        embed = self.embedding(x)\n",
    "#         the conv1 layers requires input in batch_size*hidden_size*seq_len\n",
    "        hidden = self.conv1(embed.transpose(1,2)).transpose(1,2)\n",
    "#         transfer 3d tensor to 2d tensor by merging 0\n",
    "#         hidden = F.relu(hidden.contiguous().view(-1, hidden.size(-1))).view(batch_size, seq_len, hidden.size(-1))\n",
    "        hidden = self.dropout(hidden)\n",
    "        hidden = F.relu(hidden)\n",
    "        hidden = self.conv2(hidden.transpose(1,2)).transpose(1,2)\n",
    "        hidden = self.dropout(hidden)\n",
    "#         hidden = F.relu(hidden.contiguous().view(-1, hidden.size(-1))).view(batch_size, seq_len, hidden.size(-1))\n",
    "        hidden = F.relu(hidden)   \n",
    "#       doing max pool instead\n",
    "        hidden = hidden.max(dim=1)\n",
    "        a = torch.FloatTensor(hidden[0])\n",
    "        return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chart = pd.DataFrame()\n",
    "cmodel = CNN(emb_size=100, hidden_size=100, num_layers=2, num_classes=3, vocab_size=len(id2token))\n",
    "# suppose in_features = 400\n",
    "fc_model = nn.Sequential(nn.Linear(200, 200), nn.ReLU(inplace=True), nn.Linear(200, 3))\n",
    "\n",
    "learning_rate = 3e-4\n",
    "num_epochs = 10 # number epoch to train\n",
    "\n",
    "# Criterion and Optimizer\n",
    "# CrossEntropyLoss() combines nn.LogSoftmax() and nn.NLLLoss() in one single class\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cmodel.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "\n",
    "def test_cmodel(loader, cmodel):\n",
    "    \"\"\"\n",
    "    Help function that tests the model's performance on a dataset\n",
    "    @param: loader - data loader for the dataset to test against\n",
    "    \"\"\"\n",
    "    for data1, data2, lengths, labels in loader:\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        data_batch1, data_batch2, lengths_batch, label_batch = data1, data2, lengths, labels\n",
    "        output1 = cmodel(data_batch1, lengths_batch)\n",
    "        output2 = cmodel(data_batch2, lengths_batch)\n",
    "        outputs = torch.cat([output1, output2], dim=1)\n",
    "#         print(outputs.size())\n",
    "        outputs = fc_model(outputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        predicted = outputs.max(1, keepdim=True)[1]\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels.view_as(predicted)).sum().item()          \n",
    "    return (100 * correct / total), loss\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i, (data1,data2,lengths,labels) in enumerate(train_loader):\n",
    "        outputs = 0\n",
    "        cmodel.train()\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        output1 = cmodel(data1,lengths)\n",
    "        output2 = cmodel(data2,lengths)\n",
    "        outputs = torch.cat([output1, output2], dim=1)\n",
    "#       output1: torch.Size([32, 200]), outputs: torch.Size([32, 3])\n",
    "        outputs = fc_model(outputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # validate\n",
    "    val_acc, val_loss = test_cmodel(val_loader, cmodel)    \n",
    "    predicted = outputs.max(1, keepdim=True)[1]\n",
    "    total += labels.size(0)\n",
    "    correct += predicted.eq(labels.view_as(predicted)).sum().item()\n",
    "    train_acc = 100 * correct / total\n",
    "    chart = chart.append(pd.Series([loss.item(), val_loss.item(), train_acc,val_acc]),ignore_index=True)    \n",
    "    print('Epoch: [{}/{}], Step: [{}/{}],train acc: {}, Validation Acc: {}'.format(\n",
    "                       epoch+1, num_epochs, i+1, len(train_loader), train_acc,val_acc))  \n",
    "     \n",
    "chart.columns = ['train loss','val loss', 'train acc', 'val acc']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence1    A black dog running through the forest .\n",
      "sentence2                     A dog playing outside .\n",
      "label                                      entailment\n",
      "Name: 97, dtype: object\n"
     ]
    }
   ],
   "source": [
    "stc1_val = tokenize(val_data['sentence1'])\n",
    "stc2_val = tokenize(val_data['sentence2'])\n",
    "y_val = label2int(val_data['label'])\n",
    "print(val_data.iloc[97,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull out incorrect & correct samples\n",
    "val2_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                           batch_size=1,\n",
    "                                           collate_fn=SNLI_collate_func,\n",
    "                                           shuffle=True)\n",
    "cnt = 0\n",
    "for data1, data2, lengths, labels in val2_loader:\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        data_batch1, data_batch2, lengths_batch, label_batch = data1, data2, lengths, labels\n",
    "        output1 = cmodel(data_batch1, lengths_batch)\n",
    "        output2 = cmodel(data_batch2, lengths_batch)\n",
    "        outputs = torch.cat([output1, output2], dim=1)\n",
    "        outputs = fc_model(outputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        predicted = outputs.max(1, keepdim=True)[1]\n",
    "        print(cnt, predicted, labels)\n",
    "        total += labels.size(0)\n",
    "        cnt = cnt +1\n",
    "        if cnt >100:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train loss</th>\n",
       "      <th>val loss</th>\n",
       "      <th>train acc</th>\n",
       "      <th>val acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.944406</td>\n",
       "      <td>0.982141</td>\n",
       "      <td>58.333333</td>\n",
       "      <td>57.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.827740</td>\n",
       "      <td>0.909768</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>60.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.874666</td>\n",
       "      <td>0.917046</td>\n",
       "      <td>54.166667</td>\n",
       "      <td>60.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.634986</td>\n",
       "      <td>0.857405</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.650674</td>\n",
       "      <td>0.515622</td>\n",
       "      <td>70.833333</td>\n",
       "      <td>62.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.961410</td>\n",
       "      <td>0.519126</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>62.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.658704</td>\n",
       "      <td>0.755453</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>63.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.755238</td>\n",
       "      <td>0.738587</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>63.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.317213</td>\n",
       "      <td>0.866739</td>\n",
       "      <td>87.500000</td>\n",
       "      <td>62.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.670436</td>\n",
       "      <td>0.942639</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>63.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train loss  val loss  train acc  val acc\n",
       "0    0.944406  0.982141  58.333333     57.5\n",
       "1    0.827740  0.909768  62.500000     60.5\n",
       "2    0.874666  0.917046  54.166667     60.3\n",
       "3    0.634986  0.857405  75.000000     62.0\n",
       "4    0.650674  0.515622  70.833333     62.5\n",
       "5    0.961410  0.519126  66.666667     62.6\n",
       "6    0.658704  0.755453  75.000000     63.1\n",
       "7    0.755238  0.738587  62.500000     63.7\n",
       "8    0.317213  0.866739  87.500000     62.3\n",
       "9    0.670436  0.942639  75.000000     63.1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mode 2\n",
    "chart3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train loss</th>\n",
       "      <th>val loss</th>\n",
       "      <th>train acc</th>\n",
       "      <th>val acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.830431</td>\n",
       "      <td>0.815015</td>\n",
       "      <td>54.166667</td>\n",
       "      <td>57.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.766540</td>\n",
       "      <td>0.666479</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>60.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.966648</td>\n",
       "      <td>0.630540</td>\n",
       "      <td>54.166667</td>\n",
       "      <td>61.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.831226</td>\n",
       "      <td>0.846666</td>\n",
       "      <td>58.333333</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.666718</td>\n",
       "      <td>1.890501</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>63.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.595547</td>\n",
       "      <td>1.344122</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.651425</td>\n",
       "      <td>1.344152</td>\n",
       "      <td>70.833333</td>\n",
       "      <td>63.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.482722</td>\n",
       "      <td>0.713448</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>63.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.479897</td>\n",
       "      <td>1.153279</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>63.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.603719</td>\n",
       "      <td>0.892604</td>\n",
       "      <td>79.166667</td>\n",
       "      <td>62.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train loss  val loss  train acc  val acc\n",
       "0    0.830431  0.815015  54.166667     57.8\n",
       "1    0.766540  0.666479  62.500000     60.1\n",
       "2    0.966648  0.630540  54.166667     61.4\n",
       "3    0.831226  0.846666  58.333333     63.0\n",
       "4    0.666718  1.890501  75.000000     63.2\n",
       "5    0.595547  1.344122  83.333333     63.0\n",
       "6    0.651425  1.344152  70.833333     63.2\n",
       "7    0.482722  0.713448  75.000000     63.2\n",
       "8    0.479897  1.153279  83.333333     63.7\n",
       "9    0.603719  0.892604  79.166667     62.7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mode 3\n",
    "chart4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train loss</th>\n",
       "      <th>val loss</th>\n",
       "      <th>train acc</th>\n",
       "      <th>val acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.857222</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>65.625</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.877461</td>\n",
       "      <td>0.903923</td>\n",
       "      <td>50.000</td>\n",
       "      <td>61.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.874572</td>\n",
       "      <td>1.027983</td>\n",
       "      <td>59.375</td>\n",
       "      <td>63.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.856565</td>\n",
       "      <td>0.751945</td>\n",
       "      <td>62.500</td>\n",
       "      <td>62.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.545737</td>\n",
       "      <td>1.270057</td>\n",
       "      <td>78.125</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.877181</td>\n",
       "      <td>0.743008</td>\n",
       "      <td>56.250</td>\n",
       "      <td>63.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.714999</td>\n",
       "      <td>0.759234</td>\n",
       "      <td>62.500</td>\n",
       "      <td>63.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.715825</td>\n",
       "      <td>0.628397</td>\n",
       "      <td>68.750</td>\n",
       "      <td>64.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.701119</td>\n",
       "      <td>0.507828</td>\n",
       "      <td>68.750</td>\n",
       "      <td>63.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.967130</td>\n",
       "      <td>0.698065</td>\n",
       "      <td>62.500</td>\n",
       "      <td>64.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train loss  val loss  train acc  val acc\n",
       "0    0.857222  0.765864     65.625     58.0\n",
       "1    0.877461  0.903923     50.000     61.2\n",
       "2    0.874572  1.027983     59.375     63.5\n",
       "3    0.856565  0.751945     62.500     62.7\n",
       "4    0.545737  1.270057     78.125     64.0\n",
       "5    0.877181  0.743008     56.250     63.2\n",
       "6    0.714999  0.759234     62.500     63.5\n",
       "7    0.715825  0.628397     68.750     64.1\n",
       "8    0.701119  0.507828     68.750     63.7\n",
       "9    0.967130  0.698065     62.500     64.4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mode 4\n",
    "chart5 = chart\n",
    "chart5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating on MultiNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(data):\n",
    "    mstc1_val = tokenize(data['sentence1'])\n",
    "    mstc2_val = tokenize(data['sentence2'])\n",
    "    my_val = label2int(data['label'])\n",
    "    # convert token to ID\n",
    "    mstc1_val_indices = token2index_dataset(mstc1_val)\n",
    "    mstc2_val_indices = token2index_dataset(mstc2_val)\n",
    "    # double checking\n",
    "    print (\"Val dataset size is {}\".format(len(mstc1_val_indices)))\n",
    "    \n",
    "    mval_dataset = SNLIDataset(mstc1_val_indices,mstc2_val_indices, my_val)\n",
    "    mval_loader = torch.utils.data.DataLoader(dataset=mval_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=SNLI_collate_func,\n",
    "                                           shuffle=True)\n",
    "    return mval_loader\n",
    "\n",
    "\n",
    "def evaluate(loader):\n",
    "    #for RNN\n",
    "    r_acc, r_loss = test_model(loader, model)\n",
    "    #for CNN\n",
    "    c_acc, c_loss = test_cmodel(loader, cmodel)\n",
    "    return pd.Series([r_loss.item(),c_loss.item(),r_acc,c_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val dataset size is 1016\n",
      "Val dataset size is 1002\n",
      "Val dataset size is 995\n",
      "Val dataset size is 982\n",
      "Val dataset size is 1005\n"
     ]
    }
   ],
   "source": [
    "mval_data = pd.read_table('mnli_val.tsv')\n",
    "genres = set(mval_data['genre'])\n",
    "metric = pd.DataFrame()\n",
    "\n",
    "for genre in genres:\n",
    "    group = mval_data[mval_data['genre'] == genre].drop(['genre'],axis = 1)\n",
    "    loader = read(group)\n",
    "    scores = evaluate(loader)\n",
    "    metric =  metric.append(scores,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RNN loss</th>\n",
       "      <th>CNN loss</th>\n",
       "      <th>RNN acc</th>\n",
       "      <th>CNN acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>government</th>\n",
       "      <td>1.194837</td>\n",
       "      <td>1.447474</td>\n",
       "      <td>37.598425</td>\n",
       "      <td>41.929134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slate</th>\n",
       "      <td>1.267342</td>\n",
       "      <td>1.219725</td>\n",
       "      <td>38.622754</td>\n",
       "      <td>40.818363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fiction</th>\n",
       "      <td>1.995804</td>\n",
       "      <td>0.991552</td>\n",
       "      <td>35.879397</td>\n",
       "      <td>40.301508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>travel</th>\n",
       "      <td>1.391345</td>\n",
       "      <td>0.904735</td>\n",
       "      <td>38.289206</td>\n",
       "      <td>41.955193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>telephone</th>\n",
       "      <td>1.428192</td>\n",
       "      <td>1.381033</td>\n",
       "      <td>38.109453</td>\n",
       "      <td>42.686567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            RNN loss  CNN loss    RNN acc    CNN acc\n",
       "government  1.194837  1.447474  37.598425  41.929134\n",
       "slate       1.267342  1.219725  38.622754  40.818363\n",
       "fiction     1.995804  0.991552  35.879397  40.301508\n",
       "travel      1.391345  0.904735  38.289206  41.955193\n",
       "telephone   1.428192  1.381033  38.109453  42.686567"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.index = genres\n",
    "metric.columns = ['RNN loss', 'CNN loss', 'RNN acc','CNN acc']\n",
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
